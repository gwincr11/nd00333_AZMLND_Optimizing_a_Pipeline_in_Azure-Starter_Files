# Optimizing an ML Pipeline in Azure

## Overview

This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources

- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)

## Summary

**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This data set is about bank marketing success and includes demographic information and success states. We seek to predict when bank marketing will be succesful.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best preforming model came from AutomML and was 91.7% accurate. VotingAssemble achieved this level of accuracy.

## Scikit-learn Pipeline

**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The data is setup as the demographic data persumed as affecting the marking outcome, x and the marketing outcome y. All the data is one hot encoded to be be 1 or 0. Columns like married are simply 1 or 0, columns with many options are spread out for example education becomes education.university where each options become a 0 or a 1 as represented by strings currently in the column.

The SciKit learn algorithm is using Logistic Regression to try to create a set of weights for each demographic data point until the weights approach a fit with prediction of success, which is a binary 1/0.

The training script takes 2 parameters:

- max_iter which sets the number of max allowed iterations to take on the training data.
- C This is used to regularize the weights in the model to help prevent overfitting to the training dataset.

The notebook sets up the Azure experiment and uses the train.py file along with the scikit pip environment to try out different parameter combinations in parrallel to quickly explore the possibile solutions to find the best performing combination.

**What are the benefits of the parameter sampler you chose?**
RandomParameterSampling will uniformly search a large parameter space and can be run in parrallel. This allows the pipeline to test out different parameter combinations quickly without being locked into a grid and does not exhaustively search the parameter space.

**What are the benefits of the early stopping policy you chose?**
I choose early bandit as the stopping policy, once a baseline is set for how early trained models is created any model that is showing that it is not within 90% performance of the base line will be stopped early to save resources.

## AutoML

**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

AutoML created a wide variety of models with different hyperparameters. This is neat because it take a number of known approaches to classifaction problems and tests them in parrallel against each other to find the model that best fit to the available data.

## Pipeline comparison

**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

AutoML chose a voting ensemble model, which is a collection of different classification algorithms that vote on the best answer. The ensemble model was made up of 8 different classification algorithms.

Accuracy: {'accuracy': 0.9170848315583743}

Parameters of the Best Model:

voting: Prefited Soft voting This parameter specifies the type of voting to use. Soft voting means that the predicted class is the one with the highest average predicted probability.

weights: The weights assigned to the models in the ensemble. A higher weight means the model has more influence on the final prediction.

n_jobs: None This parameter is used to specify the number of jobs to run in parallel.

flatten_transform: None This parameter signals whether the transformation is flattened.

The SciKit learn approach score a 90.8% accuracy and AutoMl found a model that performed at 91.7% accuracy. Both of these approach spun up many concurrent experiments and searched a large parameter space to find the best model fit. AutoML had an advantage as it was able to test many different classification algorithms and not just parameters into a single algorithm.

## Future work

**What are some areas of improvement for future experiments? Why might these improvements help the model?**

I think we could explore this work in 2 ways.

1. The Voting classifier seems to work better than the logistic regression algorithm. We could consider running this algorithm through hyper drive to explore a bigger parameter set and see if we can find a better model.
2. The data is very heavily weighted towards no answers. We could deal with this in a few ways such as undersampling the no answers, creating yes answer duplicates, or switching our evaluation metrics from accuracy to precision.

## Proof of cluster clean up

**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

This is in the notebook
